{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Fetch the dataset from OpenML (UCI datasets are often available here)\n",
    "poker_hand = fetch_openml(name='poker-hand', version=1, as_frame=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = poker_hand.data\n",
    "y = poker_hand.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.47\n",
      "R^2 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Encode the categorical target variable\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1. **Encoding the Target Variable**\n",
    "   - The `LabelEncoder` was used to convert the categorical target variable (`y`) into numerical labels, which is a necessary step since `LinearRegression` requires numerical inputs for both features and the target.\n",
    "   - For example, if `y` contained categories like `[\"Hand1\", \"Hand2\", \"Hand3\"]`, these would be encoded as `[0, 1, 2]`.\n",
    "\n",
    "#### 2. **Splitting the Data**\n",
    "   - The dataset was split into training and testing sets using `train_test_split`:\n",
    "     - `80%` of the data was used to train the model.\n",
    "     - `20%` was reserved for testing to evaluate its performance.\n",
    "\n",
    "#### 3. **Fitting the Linear Regression Model**\n",
    "   - A `LinearRegression` model was trained using the encoded numerical labels (`y_encoded`) as the target.\n",
    "   - Linear regression tries to find the best-fitting line to minimize the difference between predicted and true values.\n",
    "\n",
    "#### 4. **Making Predictions**\n",
    "   - Predictions (`y_pred`) were made on the test set, resulting in continuous numerical values.\n",
    "\n",
    "#### 5. **Evaluating the Model**\n",
    "   - The model's performance was evaluated using two metrics:\n",
    "     - **Mean Squared Error (MSE):** Measures the average squared difference between predicted and true values. Lower values are better.\n",
    "     - **R² Score:** Indicates how well the model explains the variance in the target variable. A value close to 1 indicates a good fit, while 0 or negative values indicate poor performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Results and Interpretation\n",
    "\n",
    "- **Mean Squared Error (MSE):** 1.47  \n",
    "  This suggests that, on average, the squared difference between the predicted and actual values is 1.47. While this is not extremely high, it doesn't provide meaningful insights because the problem involves categorical classes rather than continuous numerical values.\n",
    "\n",
    "- **R² Score:** 0.00  \n",
    "  An R² score of `0.00` means the model does not explain any of the variance in the target variable. Essentially, the linear regression model performs no better than predicting the mean value of the target.\n",
    "\n",
    "---\n",
    "\n",
    "### Why It Didn't Work\n",
    "\n",
    "Linear regression is not suitable for this problem because:\n",
    "1. **Categorical Target:** The target variable represents categories (e.g., poker hand types). Linear regression is designed for continuous numerical targets, not categorical ones.\n",
    "2. **Model Assumptions:** Linear regression assumes a linear relationship between the features and the target. For categorical data, this assumption does not hold.\n",
    "3. **Nature of the Problem:** Predicting poker hand types is inherently a classification problem, not a regression problem. The encoded numerical labels are not truly continuous, which misleads the model.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
